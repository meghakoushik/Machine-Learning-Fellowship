{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and read csv file\n",
    "data_module = pd.read_csv('Restaurant_Reviews.tsv', delimiter='\\t')\n",
    "data_module.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pre-Processing\n",
    "corpus =[]\n",
    "for i in range(0,1000):\n",
    "    review = re.sub('[^a-zA-Z]',' ',data_module['Review'][i])\n",
    "    review = review.lower()\n",
    "    review=review.split()\n",
    "    ps =PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review =' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a bag of words\n",
    "cv=CountVectorizer(max_features=1500)\n",
    "x=cv.fit_transform(corpus).toarray()\n",
    "y=data_module.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (800, 1500)\n",
      "x_test (200, 1500)\n",
      "y_train (800,)\n",
      "y_test (200,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",x_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scalling\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "\n",
      " pridiction value\n",
      " [1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0\n",
      " 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1]\n",
      "accuracy : 70.5\n",
      "\n",
      "accuracy\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65        97\n",
      "           1       0.67      0.84      0.75       103\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.72      0.70      0.70       200\n",
      "weighted avg       0.72      0.70      0.70       200\n",
      "\n",
      "confusion matrix value\n",
      "\n",
      " [[54 43]\n",
      " [16 87]]\n"
     ]
    }
   ],
   "source": [
    "class NLP:\n",
    "    def naive_bayes(self,x_train,y_train):\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(x_train,y_train)\n",
    "        return classifier\n",
    "    def predict(self,x_test,classifier):\n",
    "        y_pred= classifier.predict(x_test)\n",
    "        return y_pred\n",
    "    def accuracy(self,y_test,y_pred):\n",
    "        accuracy = accuracy_score(y_test,y_pred)\n",
    "        return accuracy\n",
    "    def confusion_matrix(self,y_test,y_pred):\n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        return cm\n",
    "def main():\n",
    "    obj= NLP()\n",
    "    \n",
    "    #fitting naive Bayes to the trainning set  model\n",
    "    classifier = obj.naive_bayes(x_train,y_train)\n",
    "    print(classifier)\n",
    "    \n",
    "    #predicting the test set\n",
    "    y_pred = obj.predict(x_test,classifier)\n",
    "    print(\"\\n pridiction value\\n\",y_pred)\n",
    "    \n",
    "    #calculating accuracy\n",
    "    accuracy = obj.accuracy(y_test,y_pred)*100\n",
    "    print(\"accuracy :\", accuracy)\n",
    "    \n",
    "    accuracy=classification_report(y_test, y_pred)\n",
    "    print(\"\\naccuracy\\n\",accuracy)\n",
    "\n",
    "    #making the confusion matrix\n",
    "    cm= obj.confusion_matrix(y_test,y_pred)\n",
    "    print(\"confusion matrix value\\n\\n\",cm)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
